{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a385adf",
   "metadata": {},
   "source": [
    "# Text Preprocessing and Sentiment analysis of r/Happy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f478465",
   "metadata": {},
   "source": [
    "Import and read the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca61d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: spacy in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (3.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: setuptools in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/gabychu/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji\n",
    "!pip3 install nltk\n",
    "!pip3 install spacy\n",
    "import pandas as pd\n",
    "import emoji as emoji\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142dee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_final = pd.read_csv(\"happy_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25eb9bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>full_link</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GoodNaturedGamer</td>\n",
       "      <td>After months of work my work with dnd.Disablit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/mnq89p...</td>\n",
       "      <td>2021-04-09 20:42:50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASAP-Broccoli</td>\n",
       "      <td>Happy 1st birthday to my best friend</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/mnot6q...</td>\n",
       "      <td>2021-04-09 19:32:31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cctrjkrfan</td>\n",
       "      <td>Neighbors moved out of the apartment complex a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/mnoo7x...</td>\n",
       "      <td>2021-04-09 19:25:31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_keiki_kitten</td>\n",
       "      <td>Lemme see ‘em</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/mnoa9w...</td>\n",
       "      <td>2021-04-09 19:06:21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Utterlybored</td>\n",
       "      <td>Two Weeks Since Shot #2 Means I Have Reached P...</td>\n",
       "      <td>...or as I call it, 2V + 14\\n\\nOff to hug the ...</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/mnmzct...</td>\n",
       "      <td>2021-04-09 18:02:50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Link_Worried</td>\n",
       "      <td>She saved a whole colony of bees. What a legend.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/m42hlv...</td>\n",
       "      <td>2021-03-13 08:45:42</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Emilena_</td>\n",
       "      <td>Officially Diagnosed with ADHD and Thrilled!!!</td>\n",
       "      <td>I feel like this has been a moment I have been...</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/m41bbi...</td>\n",
       "      <td>2021-03-13 07:09:58</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Emilena_</td>\n",
       "      <td>Officially diagnosed with ADHD today!</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/m419v2...</td>\n",
       "      <td>2021-03-13 07:06:55</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>carpet_fire</td>\n",
       "      <td>Jacket says sup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/m40kfp...</td>\n",
       "      <td>2021-03-13 06:13:04</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>TeaHC16</td>\n",
       "      <td>Throughout school, my dad would pack my lunche...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/happy/comments/m3zxcb...</td>\n",
       "      <td>2021-03-13 05:26:49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                              title  \\\n",
       "0    GoodNaturedGamer  After months of work my work with dnd.Disablit...   \n",
       "1       ASAP-Broccoli               Happy 1st birthday to my best friend   \n",
       "2          cctrjkrfan  Neighbors moved out of the apartment complex a...   \n",
       "3       _keiki_kitten                                      Lemme see ‘em   \n",
       "4        Utterlybored  Two Weeks Since Shot #2 Means I Have Reached P...   \n",
       "..                ...                                                ...   \n",
       "535      Link_Worried   She saved a whole colony of bees. What a legend.   \n",
       "536          Emilena_     Officially Diagnosed with ADHD and Thrilled!!!   \n",
       "537          Emilena_              Officially diagnosed with ADHD today!   \n",
       "538       carpet_fire                                    Jacket says sup   \n",
       "539           TeaHC16  Throughout school, my dad would pack my lunche...   \n",
       "\n",
       "                                              selftext  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4    ...or as I call it, 2V + 14\\n\\nOff to hug the ...   \n",
       "..                                                 ...   \n",
       "535                                                NaN   \n",
       "536  I feel like this has been a moment I have been...   \n",
       "537                                          [removed]   \n",
       "538                                                NaN   \n",
       "539                                                NaN   \n",
       "\n",
       "                                             full_link          created_utc  \\\n",
       "0    https://www.reddit.com/r/happy/comments/mnq89p...  2021-04-09 20:42:50   \n",
       "1    https://www.reddit.com/r/happy/comments/mnot6q...  2021-04-09 19:32:31   \n",
       "2    https://www.reddit.com/r/happy/comments/mnoo7x...  2021-04-09 19:25:31   \n",
       "3    https://www.reddit.com/r/happy/comments/mnoa9w...  2021-04-09 19:06:21   \n",
       "4    https://www.reddit.com/r/happy/comments/mnmzct...  2021-04-09 18:02:50   \n",
       "..                                                 ...                  ...   \n",
       "535  https://www.reddit.com/r/happy/comments/m42hlv...  2021-03-13 08:45:42   \n",
       "536  https://www.reddit.com/r/happy/comments/m41bbi...  2021-03-13 07:09:58   \n",
       "537  https://www.reddit.com/r/happy/comments/m419v2...  2021-03-13 07:06:55   \n",
       "538  https://www.reddit.com/r/happy/comments/m40kfp...  2021-03-13 06:13:04   \n",
       "539  https://www.reddit.com/r/happy/comments/m3zxcb...  2021-03-13 05:26:49   \n",
       "\n",
       "     score  num_comments  num_crossposts  \n",
       "0        1             1               0  \n",
       "1        1             2               0  \n",
       "2        1             3               0  \n",
       "3        1             2               0  \n",
       "4        1             3               0  \n",
       "..     ...           ...             ...  \n",
       "535      1             3               0  \n",
       "536      1             6               0  \n",
       "537      1             2               0  \n",
       "538      1             2               0  \n",
       "539      1             2               0  \n",
       "\n",
       "[540 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786564b",
   "metadata": {},
   "source": [
    "We start the sentiment analysis with text preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ea16f",
   "metadata": {},
   "source": [
    "Store all titles in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c2f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total titles scraped: 540\n"
     ]
    }
   ],
   "source": [
    "Title_all = []\n",
    "for i in happy_final.loc[:,\"title\"]:\n",
    "    Title_all.append(i)\n",
    "#print(Title_all)\n",
    "print('Total titles scraped:', len(Title_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ada9ba",
   "metadata": {},
   "source": [
    "Then, we preprocess the titles to get rid of the emojis, stopwords, and links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f74f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make all titles into a string object  \n",
    "List = Title_all\n",
    "List = [str(i) for i in List] #this makes every title into a string itself but separated by commas \n",
    "string_uncleaned = \",\". join(List) #join all the strings separated by commas \n",
    "#string_uncleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3076d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing emojis\n",
    "\n",
    "def give_emoji_free_text(text): \n",
    "    return emoji.get_emoji_regexp().sub(r'', text)\n",
    "\n",
    "emoji_free = give_emoji_free_text(string_uncleaned)\n",
    "\n",
    "#emoji_free\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb810de",
   "metadata": {},
   "source": [
    "We tokenize the words. Tokenizing breaks apart every word in the string into an individual word which would then carry it’s own “positive” or “negative” sentiment based on our sentiment analyzer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d667b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+?!!!')\n",
    "tokenized_string = tokenizer.tokenize(emoji_free)\n",
    "#print(tokenized_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d07e1a",
   "metadata": {},
   "source": [
    "Some words are uppercase while others are lowercase. We must standardize to all lower case then put it in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8967311",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case = [word.lower() for word in tokenized_string]\n",
    "\n",
    "#print(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45f7410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "#spacy.load(\"en_core_web_sm\")\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "text = lower_case \n",
    "no_stopwords = [i for i in text if not i in all_stopwords]\n",
    "\n",
    "#print(no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd7077-112e-49b6-b0d0-2299971333c9",
   "metadata": {},
   "source": [
    "Our last step in preprocessing the text is to lemmatize the words. Lemmatization allows us to query the text and returns the root/base word. \n",
    "\n",
    "Ex: running, ran, runs are all forms of the base word run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83171083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/gabychu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in no_stopwords]\n",
    "\n",
    "#print(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4b57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words originally: 49129\n",
      "number of words after taking out emojis: 49002\n",
      "number of words after tokenization: 9356\n",
      "number of words after taking out stopwords: 4579\n",
      "number of words after lemmatization 4579\n"
     ]
    }
   ],
   "source": [
    "## printing len to see how much we have cut down \n",
    "print(\"number of words originally:\", len(string_uncleaned))\n",
    "print(\"number of words after taking out emojis:\", len(emoji_free))\n",
    "print(\"number of words after tokenization:\", len(tokenized_string))\n",
    "print(\"number of words after taking out stopwords:\", len(no_stopwords))\n",
    "print(\"number of words after lemmatization\", len(lemmatized))\n",
    "#lets store the final output into a new variable \n",
    "cleaned = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce5275d8-2553-4f42-a78d-048c6ab2f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cleaned, columns=[\"word\"])\n",
    "df.to_csv('cleaned_happy_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3fa19",
   "metadata": {},
   "source": [
    "Now that we have a cleaned output, we are going to use the VADER model (Valence Aware Dictionary for Sentiment Reasoning) to calculate the polarity score (valence) of each word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
